{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(r'C:\\Users\\carlo\\GitHub\\ProjectBuffalo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import buffalo.ingestion as ingestion\n",
    "import buffalo.predictor as predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingestor = ingestion.DataIngestion(ingestion.enum.API.ADVANTAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingestor.load_data(r'cached_data/ingestion.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_symbol = 'AAPL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingestor.data['ADJUSTED_DAILY_STOCK'].symbol.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_stock = ingestor.data['ADJUSTED_DAILY_STOCK'].query('symbol == @target_symbol')[['open', 'high', 'low', 'adjusted_close', 'volume']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_stocks = ingestor.data['ADJUSTED_DAILY_STOCK'].query('symbol != \"AAPL\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for symbol in ['AAPL', 'MSFT', 'IBM', 'META']:\n",
    "    temp = other_stocks[other_stocks['symbol'] == symbol][['open', 'high', 'low', 'adjusted_close', 'volume']].rename(columns={'adjusted_close': 'close'})\n",
    "    temp.columns = symbol + '_' + temp.columns\n",
    "    target_stock = predictor.util.align_dataframe_by_time(target_stock, temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_income_statement = ingestor.data['COMPANY_INCOME_STATEMENT'].query('symbol == @target_symbol & freq == \"quarterly\"').drop(columns=['reported_currency', 'symbol', 'freq', 'function']).dropna(axis=1, how='all')\n",
    "target_balance_sheet = ingestor.data['COMPANY_BALANCE_SHEET'].query('symbol == @target_symbol & freq == \"quarterly\"').drop(columns=['reported_currency', 'symbol', 'freq', 'function']).dropna(axis=1, how='all')\n",
    "target_cash_flow = ingestor.data['COMPANY_CASH_FLOW'].query('symbol == @target_symbol & freq == \"quarterly\"').drop(columns=['reported_currency', 'symbol', 'freq', 'function', 'net_income']).dropna(axis=1, how='all')\n",
    "fed_funds_rate = ingestor.data['FEDERAL_FUNDS_RATE'][['value']].rename(columns={'value': 'effective_federal_funds_rate'}).dropna(axis=1, how='all')\n",
    "payroll = ingestor.data['NONFARM_PAYROLL'][['value']].rename(columns={'value': 'total_nonfarm_payroll'}).dropna(axis=1, how='all')\n",
    "cpi = ingestor.data['CPI'][['value']].rename(columns={'value': 'consumer_price_index'}).dropna(axis=1, how='all')\n",
    "unemployment = ingestor.data['UNEMPLOYMENT'][['value']].rename(columns={'value': 'unemployment_rate'}).dropna(axis=1, how='all')\n",
    "real_gdp = ingestor.data['REAL_GDP'][['value']].rename(columns={'value': 'real_gross_domestic_product'}).dropna(axis=1, how='all')\n",
    "real_gdp_per_capita = ingestor.data['REAL_GDP_PER_CAPITA'][['value']].rename(columns={'value': 'real_gross_domestic_product_per_capita'})\n",
    "treasury_yield = ingestor.data['TREASURY_YIELD'][['value', 'maturity']].pivot(columns=['maturity'], values=['value']).dropna(axis=1, how='all')\n",
    "treasury_yield.columns = 'treasury_yield_' + treasury_yield.columns.droplevel(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target_stock.shape)\n",
    "target_stock = predictor.util.align_dataframe_by_time(target_stock, fed_funds_rate)\n",
    "print(target_stock.shape)\n",
    "target_stock = predictor.util.align_dataframe_by_time(target_stock, payroll)\n",
    "print(target_stock.shape)\n",
    "target_stock = predictor.util.align_dataframe_by_time(target_stock, cpi)\n",
    "print(target_stock.shape)\n",
    "target_stock = predictor.util.align_dataframe_by_time(target_stock, unemployment)\n",
    "print(target_stock.shape)\n",
    "target_stock = predictor.util.align_dataframe_by_time(target_stock, real_gdp)\n",
    "print(target_stock.shape)\n",
    "target_stock = predictor.util.align_dataframe_by_time(target_stock, real_gdp_per_capita)\n",
    "print(target_stock.shape)\n",
    "target_stock = predictor.util.align_dataframe_by_time(target_stock, treasury_yield)\n",
    "print(target_stock.shape)\n",
    "#target_stock = predictor.util.align_dataframe_by_time(target_stock, target_income_statement)\n",
    "#print(target_stock.shape)\n",
    "#target_stock = predictor.util.align_dataframe_by_time(target_stock, target_balance_sheet)\n",
    "#print(target_stock.shape)\n",
    "#target_stock = predictor.util.align_dataframe_by_time(target_stock, target_cash_flow)\n",
    "#print(target_stock.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(target_stock, open('cached_data/target_stock.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_stock = pickle.load(open('cached_data/target_stock.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5246, 24)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_stock.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_data = predictor.util.TimeSeries(endog=target_stock[['close']], exog=target_stock.drop(columns='close'), seq_len=180)\n",
    "trainset, testset = time_series_data.get_traintest_splitted_dataset(0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import buffalo.predictor.models as modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = modeling.RNN(input_size=target_stock.shape[1], hidden_size=64, seq_len=180, output_size=1, num_layers=2, dropout=0.2, bidirectional=True, use_gpu=True)\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.001, weight_decay=0.001)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "training_record = modeling.train_model(rnn, optimizer, loss_func, trainset, 0.1, multi_fold_valiation=True, epochs=60, batch_size=64, save_model=True, save_path=r'cached_data/naive_rnn_bidirectional.pth') # Pointwise prediction\n",
    "modeling.test_model(rnn, testset, loss_func, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0b692f6532479aa2b946792ba1eaa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multi-fold validation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7f2c8b70a0c49348b690021db43caec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lstm = modeling.LSTM(input_size=target_stock.shape[1], hidden_size=64, seq_len=180, output_size=1, num_layers=2, dropout=0.2, bidirectional=False, use_gpu=True)\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=0.001, weight_decay=0.001)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "training_record = modeling.train_model(lstm, optimizer, loss_func, trainset, 0.1, multi_fold_valiation=True, epochs=60, batch_size=64, save_model=True, save_path=r'cached_data/naive_lstm_.pth') # Pointwise prediction\n",
    "modeling.test_model(lstm, testset, loss_func, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = modeling.LSTM(input_size=target_stock.shape[1], hidden_size=64, seq_len=180, output_size=1, num_layers=2, dropout=0.2, bidirectional=False, use_gpu=True)\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=0.001, weight_decay=0.001)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "training_record = modeling.train_model(lstm, optimizer, loss_func, trainset, 0.1, multi_fold_valiation=True, epochs=60, batch_size=64, save_model=True, save_path=r'cached_data/naive_lstm_bidirectional.pth') # Pointwise prediction\n",
    "modeling.test_model(lstm, testset, loss_func, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83d7478708aee50e506b587dee1e78eca81d8069298324b7efb66c776783145b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
